{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import os.path\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sys\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dir = r'C:\\Users\\Pundeer\\Desktop\\Data Science\\Kaggle\\amazon inventory reconciliation\\amazon inventory\\data\\metadata'\n",
    "img_dir = r'C:\\Users\\Pundeer\\Desktop\\Data Science\\Kaggle\\amazon inventory reconciliation\\amazon inventory\\data\\bin-images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3979,)\n",
      "(3979,)\n"
     ]
    }
   ],
   "source": [
    "N = range(10500)\n",
    "num_samples = 4000\n",
    "dataset_index = random.sample(N,num_samples)\n",
    "#dataset_index\n",
    "img_vec = []\n",
    "meta_vec = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    fname_img = str(dataset_index[i]).zfill(5) + '.jpg'\n",
    "    fname_meta = str(dataset_index[i]).zfill(5) + '.json'\n",
    "    jpg_path = os.path.join(img_dir,fname_img)\n",
    "    json_path = os.path.join(meta_dir,fname_meta)\n",
    "    if os.path.isfile(jpg_path) & os.path.isfile(json_path):\n",
    "        img_vec.append(fname_img)\n",
    "        meta_vec.append(fname_meta)\n",
    "        \n",
    "print(np.shape(img_vec))\n",
    "print(np.shape(meta_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2656, 1)\n",
      "(2656,)\n",
      "(2656,)\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(img_vec)\n",
    "#labels=np.zeros((num_samples,1))\n",
    "labels = []\n",
    "img_vec_less_5 = []\n",
    "meta_vec_less_5 = []\n",
    "for i in range(num_samples):\n",
    "    fname_meta = meta_vec[i]\n",
    "    fname_img = img_vec[i]\n",
    "    json_path = os.path.join(meta_dir,fname_meta)\n",
    "    f = open(json_path)\n",
    "    dataset = json.load(f)\n",
    "    expected_quantity = dataset['EXPECTED_QUANTITY']\n",
    "    if expected_quantity <= 5:\n",
    "        #print(fname)\n",
    "        #print(expected_quantity)\n",
    "        f.close()\n",
    "        #labels[i,0]=expected_quantity\n",
    "        labels.append(expected_quantity)\n",
    "        img_vec_less_5.append(fname_img)\n",
    "        meta_vec_less_5.append(fname_meta)\n",
    "        \n",
    "labels = np.array(labels, ndmin=2)\n",
    "labels = labels.T\n",
    "print(np.shape(labels))\n",
    "print(np.shape(img_vec_less_5))\n",
    "print(np.shape(meta_vec_less_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(meta_vec_less_5)\n",
    "all_arrays = []\n",
    "for i in range(num_samples):\n",
    "    fname = img_vec_less_5[i]\n",
    "    img_array = cv2.imread(os.path.join(img_dir, fname))\n",
    "    img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "    img_reshape = cv2.resize(img_array, (224,224))\n",
    "    all_arrays.append(img_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = []\n",
    "Y_ = labels\n",
    "for features in all_arrays:\n",
    "    X_.append(features)\n",
    "X_ = np.array(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2656, 224, 224, 3) (2656, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_), np.shape(Y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2124, 224, 224, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_, Y_, test_size=0.2)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2124, 6)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=8, kernel_size=(3,3), padding=\"Same\", activation=\"relu\", input_shape=(224,224,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), padding=\"Same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"Same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(6,activation=\"softmax\"))\n",
    "\n",
    "#defining optimizer\n",
    "optimizer=Adam(lr=0.001,beta_1=0.9,beta_2=0.999)\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen=ImageDataGenerator(featurewise_center = False,                           #set input mean to 0\n",
    "                           samplewise_center = False,                            #set each sample mean to 0\n",
    "                           featurewise_std_normalization = False,                #divide input datas to std\n",
    "                           samplewise_std_normalization = False,                 #divide each datas to own std\n",
    "                           zca_whitening = False,                                #dimension reduction\n",
    "                           rotation_range = 0.5,                                 #rotate 5 degree\n",
    "                           zoom_range = 0.5,                                     #zoom in-out 5%\n",
    "                           width_shift_range = 0.5,                              #shift 5%\n",
    "                           height_shift_range = 0.5,\n",
    "                           horizontal_flip = False,\n",
    "                           vertical_flip = False\n",
    "                          )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 173s 4s/step - loss: 339.6956 - accuracy: 0.2174 - val_loss: 1.7870 - val_accuracy: 0.1327\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 149s 4s/step - loss: 2.0190 - accuracy: 0.2179 - val_loss: 1.7902 - val_accuracy: 0.1925\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 147s 4s/step - loss: 1.7703 - accuracy: 0.2203 - val_loss: 1.7886 - val_accuracy: 0.1963\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 148s 4s/step - loss: 1.7442 - accuracy: 0.2299 - val_loss: 1.7846 - val_accuracy: 0.1963\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 146s 3s/step - loss: 1.7108 - accuracy: 0.2366 - val_loss: 1.7813 - val_accuracy: 0.2000\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 146s 3s/step - loss: 1.7233 - accuracy: 0.2150 - val_loss: 1.7748 - val_accuracy: 0.2075\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 146s 3s/step - loss: 1.6911 - accuracy: 0.2395 - val_loss: 1.7668 - val_accuracy: 0.2037\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 146s 3s/step - loss: 1.6907 - accuracy: 0.2313 - val_loss: 1.7678 - val_accuracy: 0.1907\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 146s 3s/step - loss: 1.6914 - accuracy: 0.2375 - val_loss: 1.7669 - val_accuracy: 0.1944\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 147s 3s/step - loss: 1.6859 - accuracy: 0.2338 - val_loss: 1.7641 - val_accuracy: 0.1888\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 50\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size = batch_size), epochs = epochs,\n",
    "                              validation_data = (x_test, y_test), steps_per_epoch = x_train.shape[0]//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "_input = Input((224,224,3)) \n",
    "\n",
    "conv1  = Conv2D(filters=8, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\n",
    "conv2  = Conv2D(filters=8, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "pool1  = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "conv3  = Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\n",
    "conv4  = Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\n",
    "pool2  = MaxPooling2D((2, 2))(conv4)\n",
    "\n",
    "conv5  = Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\n",
    "conv6  = Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\n",
    "conv7  = Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\n",
    "pool3  = MaxPooling2D((2, 2))(conv7)\n",
    "\n",
    "conv8  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\n",
    "conv9  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\n",
    "conv10 = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\n",
    "pool4  = MaxPooling2D((2, 2))(conv10)\n",
    "\n",
    "flat   = Flatten()(pool4)\n",
    "dense1 = Dense(512, activation=\"relu\")(flat)\n",
    "#drop5  = Dropout(0.25)(dense1)\n",
    "output = Dense(6, activation=\"softmax\")(dense1)\n",
    "\n",
    "vgg12_model  = Model(inputs=_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "vgg12_model.compile(optimizer = Adam(), loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen16 = ImageDataGenerator(featurewise_center = False,                         #set input mean to 0\n",
    "                             samplewise_center = False,                            #set each sample mean to 0\n",
    "                             featurewise_std_normalization = False,                #divide input datas to std\n",
    "                             samplewise_std_normalization = False,                 #divide each datas to own std\n",
    "                             zca_whitening = False,                                #dimension reduction\n",
    "                             rotation_range = 0.5,                                 #rotate 5 degree\n",
    "                             zoom_range = 0.5,                                     #zoom in-out 5%\n",
    "                             width_shift_range = 0.5,                              #shift 5%\n",
    "                             height_shift_range = 0.5,\n",
    "                             horizontal_flip = False,\n",
    "                             vertical_flip = False\n",
    "                            )\n",
    "datagen16.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "42/42 [==============================] - 436s 10s/step - loss: 1.9013 - accuracy: 0.2218 - val_loss: 1.6352 - val_accuracy: 0.2049\n",
      "Epoch 2/5\n",
      "42/42 [==============================] - 490s 12s/step - loss: 1.6390 - accuracy: 0.2445 - val_loss: 1.6309 - val_accuracy: 0.2368\n",
      "Epoch 3/5\n",
      "42/42 [==============================] - 566s 13s/step - loss: 1.6354 - accuracy: 0.2594 - val_loss: 1.6164 - val_accuracy: 0.2406\n",
      "Epoch 4/5\n",
      "42/42 [==============================] - 541s 13s/step - loss: 1.6289 - accuracy: 0.2473 - val_loss: 1.6062 - val_accuracy: 0.2444\n",
      "Epoch 5/5\n",
      "42/42 [==============================] - 581s 14s/step - loss: 1.6123 - accuracy: 0.2493 - val_loss: 1.6064 - val_accuracy: 0.2312\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "#model fitting\n",
    "history1 = vgg12_model.fit_generator(datagen16.flow(x_train,y_train, batch_size = batch_size), epochs = epochs,\n",
    "                              validation_data = (x_test, y_test), steps_per_epoch = x_train.shape[0]//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, TimeDistributed, LSTM, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, (3,3), activation='relu'), input_shape=(1, 224, 224, 3)))\n",
    "model.add(TimeDistributed(MaxPool2D(pool_size=(2,2),strides=(2,2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(64, (3,3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPool2D(pool_size=(2,2),strides=(2,2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(64, activation='relu', return_sequences=False))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.compile('adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 2/5\n",
      "Epoch 3/5\n",
      "Epoch 4/5\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16f04494860>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train.reshape(2124, 1, 224,224,3), y_train, batch_size = 50, epochs = 5, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/532 [========>.....................] - ETA: 32s"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test.reshape(532,1,224,224,3), y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [5.110257491104571, 5.097093937536193, 5.096988317881151, 5.09698826242975, 5.096988334494122]}\n"
     ]
    }
   ],
   "source": [
    "print(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (2124, 1, 224, 224, 3))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-4fca50bcf6f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#model fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m history2 = model.fit_generator(datagen16.flow(x_train.reshape(2124, 1, 224,224,3) ,y_train, batch_size = batch_size), epochs = epochs,\n\u001b[0m\u001b[0;32m      6\u001b[0m                               validation_data = (x_test.reshape(532, 1, 224,224,3), y_test))\n",
      "\u001b[1;32m~\\.conda\\envs\\friday\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow\u001b[1;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         )\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\friday\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m             dtype=dtype)\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\friday\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[0;32m    115\u001b[0m             raise ValueError('Input data in `NumpyArrayIterator` '\n\u001b[0;32m    116\u001b[0m                              \u001b[1;34m'should have rank 4. You passed an array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                              'with shape', self.x.shape)\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[0mchannels_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_last'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchannels_axis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (2124, 1, 224, 224, 3))"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "#model fitting\n",
    "history2 = model.fit_generator(datagen16.flow(x_train.reshape(2124, 1, 224,224,3) ,y_train, batch_size = batch_size), epochs = epochs,\n",
    "                              validation_data = (x_test.reshape(532, 1, 224,224,3), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
